{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA + Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "from impyute.imputation.cs import fast_knn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "# %matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set sandbox_mode boolean for image building\n",
    "* if sandbox_mode = True: faster to run, but images won't be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandbox_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_mask(df):\n",
    "    type_mask = []\n",
    "    for i in df.dtypes:\n",
    "        if str(i).startswith('float') or str(i).startswith('int'): # or str(i).startswith('bool')\n",
    "            type_mask.append(True)\n",
    "        else: type_mask.append(False)\n",
    "    num_cols = list(np.array(df.columns)[type_mask])\n",
    "    other_cols = list(np.array(df.columns)[[not elem for elem in type_mask]])\n",
    "    \n",
    "    return num_cols, other_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions related to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(df):\n",
    "    total = df.isnull().sum()\n",
    "    percent = (df.isnull().sum()/df.isnull().count())\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['total', 'percent_missing'])\n",
    "    missing_data['percent_missing'] = missing_data['percent_missing']\n",
    "    missing_data['percent_missing'] = missing_data['percent_missing'].apply(lambda x: round(x,2))\n",
    "    \n",
    "    return missing_data\n",
    "\n",
    "def drop_missing_from_threshold(df, row_threshold, col_threshold):\n",
    "    row_count, col_count = df.shape\n",
    "    # drop columns according to threshold of missing; use mask of columns which have less missing than threshold\n",
    "    df = df.iloc[:, (df_missing['percent_missing'] < col_threshold).to_list()]\n",
    "    \n",
    "    # drop row according to threshold of missing\n",
    "    n_cols = df.shape[1]\n",
    "    df['ratio_mis'] = df.apply(lambda x: (n_cols - x.count())/n_cols, axis=1)\n",
    "    df = df[df['ratio_mis']<row_threshold]\n",
    "    df.drop(['ratio_mis'], axis=1, inplace=True)\n",
    "    \n",
    "    # count number of removals\n",
    "    row_count_new, col_count_new = df.shape\n",
    "    row_count_removal = row_count - row_count_new\n",
    "    col_count_removal = col_count - col_count_new\n",
    "    print('{} rows and {} columns were removed from database'.format(row_count_removal, col_count_removal))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def apply_imputation(df, method = 'knn', k=30, manual_val=-1):\n",
    "    try:\n",
    "        assert method in ['knn', 'mode', 'median', -1, 'manual']\n",
    "    except AssertionError:\n",
    "        raise ValueError('error: select a correct method for imputation: [knn, mode, median, -1, manual]')\n",
    "        \n",
    "    if method == 'knn':\n",
    "        sys.setrecursionlimit(100000) #Increase the recursion limit of the OS\n",
    "        numerical_cols, other_cols = get_numerical_mask(df)\n",
    "        \n",
    "#         df =  StandardScaler().fit_transform(df) # scale for knn to work properly (it's distance based)\n",
    "\n",
    "        # start the KNN training\n",
    "        imputed_training = fast_knn(df[numerical_cols], k=30)\n",
    "\n",
    "        # retrieve column names\n",
    "        imp_cols = imputed_training.columns.to_list()\n",
    "        imputed_training.rename({imp_cols[i]: numerical_cols[i] for i in range(len(imp_cols))}, axis = 1, inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        other_cols.append('id')\n",
    "        df = df[other_cols].merge(imputed_training, left_index=True, right_index=True)\n",
    "        df.set_index('id', inplace=True)\n",
    "        \n",
    "    elif method == 'mode':\n",
    "        df.fillna(data.mode().iloc[0], inplace=True)\n",
    "        \n",
    "    elif method == 'median':\n",
    "        df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    elif method == -1:\n",
    "        df.fillna(-1, inplace=True)\n",
    "    \n",
    "    elif method == 'manual':\n",
    "        df.fillna(manual_val, inplace=True)\n",
    "        \n",
    "    try:\n",
    "        assert df[df.isna().any(axis=1)].shape[0] == 0\n",
    "    except AssertionError:\n",
    "        raise ValueError('there are still missing values')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions related to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_standard_deviation_tol(df, tol=3):\n",
    "    #scale data for operation\n",
    "    df = pd.DataFrame(StandardScaler().fit_transform(df[numerical_cols]))\n",
    "    \n",
    "    z = np.abs(stats.zscore(df))\n",
    "    z = pd.DataFrame(z, columns = df.columns, index=df.index)\n",
    "    z.fillna(0, inplace=True)\n",
    "    for col in z.columns[2:]:\n",
    "        z = z[z[col]<tol]\n",
    "    print(\"{0:.2%} of data was removed after dealing with outliers\".format((df.shape[0]-z.shape[0])/df.shape[0]))\n",
    "    df = df.loc[z.index, :]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def apply_isolation_forest(df, contamination=0.05):\n",
    "    clf = IsolationForest(max_samples='auto', contamination=contamination, random_state=42) # contamination='auto' or 0.05\n",
    "    clf.fit(df)\n",
    "\n",
    "    outlier_pred = clf.predict(df)\n",
    "    print('number of outliers:', np.count_nonzero(outlier_pred == -1), 'from a total of {}'.format(len(outlier_pred)))\n",
    "    print('percentage of outliers: {0:.0%}'.format(np.count_nonzero(outlier_pred == -1)/np.count_nonzero(outlier_pred == 1)))\n",
    "    \n",
    "    return outlier_pred\n",
    "\n",
    "def get_outliers(df, label, cols, method = 'isolation_forest', if_contamination = 0.05, z_tol = 3):\n",
    "\n",
    "    if method == 'isolation_forest':\n",
    "        outliers = apply_isolation_forest(df, if_contamination)\n",
    "    elif method == 'standard_deviation_tol':\n",
    "        df = apply_standard_deviation_tol(df, z_tol)\n",
    "    \n",
    "    print(len(outliers))\n",
    "    return outliers, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = os.path.join('..', 'data', '02_intermediate')\n",
    "outputs = os.path.join('..', 'data', '02_intermediate')\n",
    "reports = os.path.join('..', 'data', '06_reporting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data               = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "data_test          = pd.read_csv(os.path.join(inputs, 'X_test.csv'), index_col='id')\n",
    "y_train            = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id')\n",
    "y_test             = pd.read_csv(os.path.join(inputs, 'y_test.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (559, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preset_1</th>\n",
       "      <th>preset_2</th>\n",
       "      <th>cycle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibrationx</th>\n",
       "      <th>vibrationy</th>\n",
       "      <th>vibrationz</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>anomaly_count_lag10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.235186</td>\n",
       "      <td>47.657254</td>\n",
       "      <td>46.441769</td>\n",
       "      <td>64.820327</td>\n",
       "      <td>66.454520</td>\n",
       "      <td>44.483250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.807234</td>\n",
       "      <td>63.172076</td>\n",
       "      <td>62.005951</td>\n",
       "      <td>80.714431</td>\n",
       "      <td>81.246405</td>\n",
       "      <td>60.228715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.027536</td>\n",
       "      <td>83.032190</td>\n",
       "      <td>82.642110</td>\n",
       "      <td>98.254386</td>\n",
       "      <td>98.785196</td>\n",
       "      <td>80.993479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.716242</td>\n",
       "      <td>100.508634</td>\n",
       "      <td>122.362321</td>\n",
       "      <td>121.363429</td>\n",
       "      <td>118.652538</td>\n",
       "      <td>80.315567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.989054</td>\n",
       "      <td>51.764833</td>\n",
       "      <td>42.514302</td>\n",
       "      <td>61.037910</td>\n",
       "      <td>50.716469</td>\n",
       "      <td>64.245166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preset_1  preset_2  cycle  temperature    pressure  vibrationx  \\\n",
       "id                                                                   \n",
       "0          3         6    1.0    44.235186   47.657254   46.441769   \n",
       "1          2         4    2.0    60.807234   63.172076   62.005951   \n",
       "2          2         1    3.0    79.027536   83.032190   82.642110   \n",
       "3          2         3    4.0    79.716242  100.508634  122.362321   \n",
       "4          2         5    5.0    39.989054   51.764833   42.514302   \n",
       "\n",
       "    vibrationy  vibrationz  frequency  lag_1  lag_2  lag_3  \\\n",
       "id                                                           \n",
       "0    64.820327   66.454520  44.483250      0      0      0   \n",
       "1    80.714431   81.246405  60.228715      0      0      0   \n",
       "2    98.254386   98.785196  80.993479      0      0      0   \n",
       "3   121.363429  118.652538  80.315567      0      0      0   \n",
       "4    61.037910   50.716469  64.245166      0      0      0   \n",
       "\n",
       "    anomaly_count_lag10  \n",
       "id                       \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataset dimensions:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct data types\n",
    "for c in ['preset_1', 'preset_2']:\n",
    "    data[c] = data[c].astype('object')\n",
    "    \n",
    "numerical_cols, other_cols = get_numerical_mask(data)\n",
    "numerical_cols.remove('cycle') # remove cycle as it is not important for treatment\n",
    "other_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'pressure',\n",
       " 'vibrationx',\n",
       " 'vibrationy',\n",
       " 'vibrationz',\n",
       " 'frequency',\n",
       " 'lag_1',\n",
       " 'lag_2',\n",
       " 'lag_3',\n",
       " 'anomaly_count_lag10']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking  for possible anomalies in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibrationx</th>\n",
       "      <th>vibrationy</th>\n",
       "      <th>vibrationz</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>anomaly_count_lag10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>68.702203</td>\n",
       "      <td>78.538801</td>\n",
       "      <td>73.825405</td>\n",
       "      <td>72.726209</td>\n",
       "      <td>72.315758</td>\n",
       "      <td>68.632622</td>\n",
       "      <td>0.078712</td>\n",
       "      <td>0.064401</td>\n",
       "      <td>0.051878</td>\n",
       "      <td>0.533095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>161.513673</td>\n",
       "      <td>26.910673</td>\n",
       "      <td>33.432985</td>\n",
       "      <td>33.070305</td>\n",
       "      <td>33.054461</td>\n",
       "      <td>28.803297</td>\n",
       "      <td>29.686956</td>\n",
       "      <td>0.269530</td>\n",
       "      <td>0.245685</td>\n",
       "      <td>0.221980</td>\n",
       "      <td>1.493797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.089354</td>\n",
       "      <td>3.480279</td>\n",
       "      <td>3.846343</td>\n",
       "      <td>10.057744</td>\n",
       "      <td>18.784169</td>\n",
       "      <td>4.380101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.500000</td>\n",
       "      <td>50.486989</td>\n",
       "      <td>54.716829</td>\n",
       "      <td>49.873770</td>\n",
       "      <td>48.300788</td>\n",
       "      <td>50.776070</td>\n",
       "      <td>45.630488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>65.601683</td>\n",
       "      <td>75.068984</td>\n",
       "      <td>69.032209</td>\n",
       "      <td>65.803573</td>\n",
       "      <td>69.795434</td>\n",
       "      <td>66.184626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>419.500000</td>\n",
       "      <td>80.347985</td>\n",
       "      <td>98.918699</td>\n",
       "      <td>93.151613</td>\n",
       "      <td>93.627271</td>\n",
       "      <td>89.900474</td>\n",
       "      <td>89.846839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>255.607829</td>\n",
       "      <td>189.995681</td>\n",
       "      <td>230.861142</td>\n",
       "      <td>193.569947</td>\n",
       "      <td>230.951134</td>\n",
       "      <td>178.090303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cycle  temperature    pressure  vibrationx  vibrationy  \\\n",
       "count  559.000000   559.000000  559.000000  559.000000  559.000000   \n",
       "mean   280.000000    68.702203   78.538801   73.825405   72.726209   \n",
       "std    161.513673    26.910673   33.432985   33.070305   33.054461   \n",
       "min      1.000000     2.089354    3.480279    3.846343   10.057744   \n",
       "25%    140.500000    50.486989   54.716829   49.873770   48.300788   \n",
       "50%    280.000000    65.601683   75.068984   69.032209   65.803573   \n",
       "75%    419.500000    80.347985   98.918699   93.151613   93.627271   \n",
       "max    559.000000   255.607829  189.995681  230.861142  193.569947   \n",
       "\n",
       "       vibrationz   frequency       lag_1       lag_2       lag_3  \\\n",
       "count  559.000000  559.000000  559.000000  559.000000  559.000000   \n",
       "mean    72.315758   68.632622    0.078712    0.064401    0.051878   \n",
       "std     28.803297   29.686956    0.269530    0.245685    0.221980   \n",
       "min     18.784169    4.380101    0.000000    0.000000    0.000000   \n",
       "25%     50.776070   45.630488    0.000000    0.000000    0.000000   \n",
       "50%     69.795434   66.184626    0.000000    0.000000    0.000000   \n",
       "75%     89.900474   89.846839    0.000000    0.000000    0.000000   \n",
       "max    230.951134  178.090303    1.000000    1.000000    1.000000   \n",
       "\n",
       "       anomaly_count_lag10  \n",
       "count           559.000000  \n",
       "mean              0.533095  \n",
       "std               1.493797  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max               9.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing data\n",
    "usually, missing data is solved by filling it with some metric such as median. If the number of missing data in some entry is too high, we must evaluate for the removal of those entries.\n",
    "For categorical with missing data, if you want to encode missing values, first change its type to a string:\n",
    "```python\n",
    "a[pd.isnull(a)]  = 'NaN'\n",
    "```\n",
    "Some refs:\n",
    "* https://stackoverflow.com/questions/36808434/label-encoder-encoding-missing-values\n",
    "\n",
    "About the missing values, we can't assume beforehand if those are Missing at Random (MAR) or Missing not at Random (MNAR). Further investigation would be necessary to properly decide over how to handle it.\n",
    "\n",
    "For now, I am assuming they are Missing at Random. So I will remove some of them through a threshold, and apply imputation for the rest. By applying a proper imputation I observed a slight improvement over the score.\n",
    "\n",
    "The catch is that applying imputation over euclidean distances can be extremely imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns and rows for threshold of missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED LIST OF MISSING VALUES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total, percent_missing]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('SORTED LIST OF MISSING VALUES')\n",
    "df_missing = get_missing(data)\n",
    "df_missing_vis = df_missing[df_missing['total'] > 0]\n",
    "df_missing_vis['percent_missing'] = df_missing_vis['percent_missing'].apply(lambda x: round(x, 2))\n",
    "# df_missing_vis.sort_values(by='percent_missing', ascending=False).head(20)\n",
    "df_missing_vis.sort_values(by='percent_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mis_threshold = 0.8\n",
    "row_mis_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows and 0 columns were removed from database\n"
     ]
    }
   ],
   "source": [
    "data = drop_missing_from_threshold(data, row_mis_threshold, col_mis_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize rows with missing\n",
    "we already know that the critical columns are related to geo_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preset_1</th>\n",
       "      <th>preset_2</th>\n",
       "      <th>cycle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibrationx</th>\n",
       "      <th>vibrationy</th>\n",
       "      <th>vibrationz</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>anomaly_count_lag10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [preset_1, preset_2, cycle, temperature, pressure, vibrationx, vibrationy, vibrationz, frequency, lag_1, lag_2, lag_3, anomaly_count_lag10]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandbox_mode = True\n",
    "if sandbox_mode:\n",
    "    print('number of missing:', data[data.isna().any(axis=1)].shape[0])\n",
    "data[data.isna().any(axis=1)].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputation of missing values\n",
    "For continuous values, I would prefer knn over median, but it depends on normalized dataset. Nevertheless, we don't have missing on continuous datasets, even though we could encode categorical data. But the encoding step wasn't organized to precede this notebook, so I will stick to 'mode', which imputes the most frequent value.\n",
    "\n",
    "Some refs:\n",
    "* https://jamesrledoux.com/code/imputation#:~:text=One%20approach%20to%20imputing%20categorical,given%20in%20Pandas'%20value_counts%20function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the apply_imputation function accepts the following methods: knn, median, mode, or -1 (impute as category -1 [for categorical vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation over numerical variables\n",
    "data[numerical_cols] = data[numerical_cols].astype(float)\n",
    "if data[numerical_cols].isnull().values.any():\n",
    "    data = apply_imputation(data, method = 'knn', k = 30)\n",
    "\n",
    "# imputation over categorical variables\n",
    "if data[other_cols].isnull().values.any():\n",
    "    data[other_cols] = apply_imputation(data[other_cols], method = 'mode', k = 30)\n",
    "    \n",
    "# manual imputation on lag and forecast variables\n",
    "manual_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "if data[manual_cols].isnull().values.any():\n",
    "    data[manual_cols] = apply_imputation(data[manual_cols], method = 'manual', manual_val = False)\n",
    "# data_test['y'].fillna(value=data_test['y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preset_1</th>\n",
       "      <th>preset_2</th>\n",
       "      <th>cycle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibrationx</th>\n",
       "      <th>vibrationy</th>\n",
       "      <th>vibrationz</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>anomaly_count_lag10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.235186</td>\n",
       "      <td>47.657254</td>\n",
       "      <td>46.441769</td>\n",
       "      <td>64.820327</td>\n",
       "      <td>66.454520</td>\n",
       "      <td>44.483250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.807234</td>\n",
       "      <td>63.172076</td>\n",
       "      <td>62.005951</td>\n",
       "      <td>80.714431</td>\n",
       "      <td>81.246405</td>\n",
       "      <td>60.228715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.027536</td>\n",
       "      <td>83.032190</td>\n",
       "      <td>82.642110</td>\n",
       "      <td>98.254386</td>\n",
       "      <td>98.785196</td>\n",
       "      <td>80.993479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.716242</td>\n",
       "      <td>100.508634</td>\n",
       "      <td>122.362321</td>\n",
       "      <td>121.363429</td>\n",
       "      <td>118.652538</td>\n",
       "      <td>80.315567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.989054</td>\n",
       "      <td>51.764833</td>\n",
       "      <td>42.514302</td>\n",
       "      <td>61.037910</td>\n",
       "      <td>50.716469</td>\n",
       "      <td>64.245166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>555.0</td>\n",
       "      <td>44.926109</td>\n",
       "      <td>45.128385</td>\n",
       "      <td>55.084454</td>\n",
       "      <td>44.829898</td>\n",
       "      <td>54.419924</td>\n",
       "      <td>62.405853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>556.0</td>\n",
       "      <td>59.080631</td>\n",
       "      <td>60.468110</td>\n",
       "      <td>75.435527</td>\n",
       "      <td>59.438649</td>\n",
       "      <td>75.087669</td>\n",
       "      <td>83.777042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>557.0</td>\n",
       "      <td>75.732972</td>\n",
       "      <td>74.688730</td>\n",
       "      <td>95.181253</td>\n",
       "      <td>74.645044</td>\n",
       "      <td>95.769773</td>\n",
       "      <td>115.773835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>558.0</td>\n",
       "      <td>65.867720</td>\n",
       "      <td>62.089807</td>\n",
       "      <td>44.304732</td>\n",
       "      <td>44.142188</td>\n",
       "      <td>45.676147</td>\n",
       "      <td>45.099925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>559.0</td>\n",
       "      <td>89.782892</td>\n",
       "      <td>93.328654</td>\n",
       "      <td>54.025396</td>\n",
       "      <td>71.238085</td>\n",
       "      <td>54.401119</td>\n",
       "      <td>53.906128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    preset_1 preset_2  cycle  temperature    pressure  vibrationx  vibrationy  \\\n",
       "id                                                                              \n",
       "0          3        6    1.0    44.235186   47.657254   46.441769   64.820327   \n",
       "1          2        4    2.0    60.807234   63.172076   62.005951   80.714431   \n",
       "2          2        1    3.0    79.027536   83.032190   82.642110   98.254386   \n",
       "3          2        3    4.0    79.716242  100.508634  122.362321  121.363429   \n",
       "4          2        5    5.0    39.989054   51.764833   42.514302   61.037910   \n",
       "..       ...      ...    ...          ...         ...         ...         ...   \n",
       "554        3        8  555.0    44.926109   45.128385   55.084454   44.829898   \n",
       "555        1        5  556.0    59.080631   60.468110   75.435527   59.438649   \n",
       "556        1        7  557.0    75.732972   74.688730   95.181253   74.645044   \n",
       "557        1        8  558.0    65.867720   62.089807   44.304732   44.142188   \n",
       "558        1        1  559.0    89.782892   93.328654   54.025396   71.238085   \n",
       "\n",
       "     vibrationz   frequency  lag_1  lag_2  lag_3  anomaly_count_lag10  \n",
       "id                                                                     \n",
       "0     66.454520   44.483250    0.0    0.0    0.0                  0.0  \n",
       "1     81.246405   60.228715    0.0    0.0    0.0                  0.0  \n",
       "2     98.785196   80.993479    0.0    0.0    0.0                  0.0  \n",
       "3    118.652538   80.315567    0.0    0.0    0.0                  0.0  \n",
       "4     50.716469   64.245166    0.0    0.0    0.0                  0.0  \n",
       "..          ...         ...    ...    ...    ...                  ...  \n",
       "554   54.419924   62.405853    1.0    1.0    1.0                  5.0  \n",
       "555   75.087669   83.777042    0.0    0.0    0.0                  4.0  \n",
       "556   95.769773  115.773835    0.0    0.0    0.0                  3.0  \n",
       "557   45.676147   45.099925    0.0    0.0    0.0                  2.0  \n",
       "558   54.401119   53.906128    0.0    0.0    0.0                  2.0  \n",
       "\n",
       "[559 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['lag_1', 'lag_2', 'lag_3']:\n",
    "    data[col] = data[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anomaly detection\n",
    "remove outliers from choosing one of the following methods: isolation_forest, standard_deviation_tol (using z_score on standardized version)\n",
    "\n",
    "other parameters are:\n",
    "* if_contamination: isolation forest level of contamination\n",
    "* z_tol: tolerance for standard deviation (if using zscore)\n",
    "\n",
    "It is not advisable to remove outliers without proper consideration, but I lacked time to analyse it. So I used a conservative approach to remove them (low contamination threshold = few removals)\n",
    "\n",
    "Some interesting refs:\n",
    "* https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "* https://towardsdatascience.com/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2\n",
    "* https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomaly_count(df, lag=10):\n",
    "    for i in range(0,df.shape[0]-lag):\n",
    "        window = df.loc[i:i+lag,:][['if_anomaly']]\n",
    "        out_count = window[window['if_anomaly'] == -1].shape[0]\n",
    "        df.loc[df.index[i+lag],'anomaly_count_lag10'] = out_count\n",
    "    \n",
    "\n",
    "    for i in range(0, lag):\n",
    "        window = df.loc[0:i,:][['if_anomaly']]\n",
    "        out_count = window[window['if_anomaly'] == -1].shape[0]\n",
    "        df.loc[df.index[i],'anomaly_count_lag10'] = out_count\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of outliers: 28 from a total of 559\n",
      "percentage of outliers: 5%\n",
      "559\n",
      "number of outliers: 40 from a total of 799\n",
      "percentage of outliers: 5%\n",
      "799\n"
     ]
    }
   ],
   "source": [
    "# temporarily add train to test data for lagged info (no leakage here)\n",
    "test_start = data_test.index[0]\n",
    "data_test = data.append(data_test)\n",
    "\n",
    "# get outliers on train data\n",
    "data['if_anomaly'], _ = get_outliers(data[numerical_cols], y_train, numerical_cols, \n",
    "                                                  method = 'isolation_forest', if_contamination = 0.05)\n",
    "# get column with count of preceding anomalies\n",
    "data = get_anomaly_count(data, lag=10)\n",
    "    \n",
    "# get outliers on test data (needs trainset)\n",
    "\n",
    "data_test['if_anomaly'], _ = get_outliers(data_test[numerical_cols], y_train, numerical_cols, \n",
    "                                                  method = 'isolation_forest', if_contamination = 0.05)\n",
    "data_test = get_anomaly_count(data_test, lag=10)\n",
    "\n",
    "# removes trainset again\n",
    "data_test = data_test[data_test.index >= test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_data = data[data['if_anomaly'] == -1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ploting_dict = {'filename': 'outlier_analysis', 'xlabel': 'feature', 'ylabel': 'outlier count', \n",
    "                'title': 'number of outliers per feature'}\n",
    "\n",
    "plot_outliers(get_outlier_dict(outliers_data), ploting_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier removal isn't justified for this database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_outliers:\n",
    "    data = data[data['if_anomaly'] == 1]\n",
    "    y_train = y_train[y_train.index.isin(data.index.to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['if_anomaly'], axis=1, inplace=True)\n",
    "data_test.drop(['if_anomaly'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose response variable\n",
    "current y is the 'Failed' variable, but we might decide to change it to y_forecast1, which considers Failures on T+1.\n",
    "\n",
    "One of those variables must be dropped."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data['y'] = data['y_forecast1']\n",
    "data_test['y'] = data_test['y_forecast1']\n",
    "\n",
    "data.drop(['y_forecast1'], axis=1, inplace=True)\n",
    "data_test.drop(['y_forecast1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize pairwise relations\n",
    "When datasets have just a few variables (10–15), pairplots allow for a quick visual inspection of those relations, as well as bariable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols, other_cols = get_numerical_mask(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = int(len(numerical_cols)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sandbox_mode:\n",
    "    data_vis = data[numerical_cols[:separator]]\n",
    "    data_vis['y'] = y_train['y']\n",
    "    print('visualize pairplots')\n",
    "    sns.pairplot(data_vis, plot_kws={'alpha': 0.1});\n",
    "    plt.savefig(os.path.join(reports,'01_pairplots_1.jpg'), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sandbox_mode:\n",
    "    data_vis = data[numerical_cols[separator:]]\n",
    "    data_vis['y'] = y_train['y']\n",
    "    print('visualize pairplots')\n",
    "    sns.pairplot(data_vis, plot_kws={'alpha': 0.1});\n",
    "    plt.savefig(os.path.join(reports,'01_pairplots_2.jpg'), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if data is imbalanced\n",
    "When data is imbalanced, we must evaluate for solutions such as oversampling or undersamplig, which might be done with techniques such as SMOTE (Synthetic Minority Oversampling Technique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = sns.color_palette()\n",
    "classif = y_train['y'].value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(classif.index, classif.values, alpha=0.8, color=color[0])\n",
    "plt.ylabel('Number of occurrences', fontsize=12)\n",
    "plt.xlabel('Failed', fontsize=12)\n",
    "plt.plot()\n",
    "plt.savefig(os.path.join(reports,'imbalance.jpg'), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    733\n",
       "1.0     66\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = y['y'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio between classes: 11.11\n",
      "\r\n",
      "Check proportions below:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.917397\n",
       "1.0    0.082603\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ratio between classes:',round(counts[0]/counts[1],2))\n",
    "print('\\r\\nCheck proportions below:')\n",
    "y['y'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description (2nd round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "if sandbox_mode:\n",
    "    print(data.shape[0])\n",
    "    print(y_train.shape[0])\n",
    "    data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(outputs, 'X_train.csv'))\n",
    "data_test.to_csv(os.path.join(outputs, 'X_test.csv'))\n",
    "\n",
    "y_train.to_csv(os.path.join(outputs, 'y_train.csv'))\n",
    "y_test.to_csv(os.path.join(outputs, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
