{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, df_test, testing = False):\n",
    "#     df = df.copy()\n",
    "    categories_dict = {}\n",
    "    \n",
    "    temp_merge = df.append(df_test)\n",
    "    for cat in temp_merge.columns:\n",
    "        if temp_merge[cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(temp_merge[cat].unique())\n",
    "            if testing:\n",
    "                print(\"Numero de categorias para variavel '{}': {} \".format(cat,temp_merge[cat].unique().size))\n",
    "\n",
    "    if testing:\n",
    "        print()\n",
    "        print(list(categories_dict.keys()))\n",
    "        \n",
    "    enc = OrdinalEncoder(categories=list(categories_dict.values()))\n",
    "    trained_encoder = enc.fit(df[list(categories_dict.keys())])\n",
    "    \n",
    "    # transform train and test\n",
    "    df[list(categories_dict.keys())] = trained_encoder.transform(df[list(categories_dict.keys())])\n",
    "    df_test[list(categories_dict.keys())] = trained_encoder.transform(df_test[list(categories_dict.keys())])\n",
    "\n",
    "    if testing:\n",
    "        print(categories_dict)\n",
    "    \n",
    "    return df, df_test\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    print('Quantity of columns before one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    df_oldcols = df.columns.to_list()\n",
    "    df = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n",
    "    \n",
    "    print('Quantity of columns after one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    # rename columns to show which are dummies\n",
    "    onehot_cols = list(set(df.columns.to_list()) - set(df_oldcols))\n",
    "    onehot_cols_renaming = {col: 'dummy_'+col.replace('-', '_') for col in onehot_cols}\n",
    "    df.rename(columns = onehot_cols_renaming, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = os.path.join('..', 'data', '02_intermediate')\n",
    "outputs = os.path.join('..', 'data', '03_processed')\n",
    "reports = os.path.join('..', 'data', '06_reporting')\n",
    "\n",
    "ord_dict = {}\n",
    "ord_dict['X_train'] = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "ord_dict['X_test'] = pd.read_csv(os.path.join(inputs, 'X_test.csv'), index_col='id')\n",
    "\n",
    "onehot_dict = copy.deepcopy(ord_dict)\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id') \n",
    "y_test = pd.read_csv(os.path.join(inputs, 'y_test.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df = pd.read_csv(os.path.join(reports, 'data_types.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count categorical data unique values\n",
    "Check both train and test. Any inconsistency between them should be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "checking number of categories for X_train\n",
      "Numero de categorias para variavel 'productcd': 5 \n",
      "Numero de categorias para variavel 'card4': 4 \n",
      "Numero de categorias para variavel 'card6': 2 \n",
      "Numero de categorias para variavel 'p_emaildomain': 54 \n",
      "Numero de categorias para variavel 'r_emaildomain': 40 \n",
      "Numero de categorias para variavel 'm4': 3 \n",
      "\r\n",
      "checking number of categories for X_test\n",
      "Numero de categorias para variavel 'card4': 4 \n",
      "Numero de categorias para variavel 'card6': 3 \n",
      "Numero de categorias para variavel 'm4': 3 \n",
      "Numero de categorias para variavel 'p_emaildomain': 45 \n",
      "Numero de categorias para variavel 'productcd': 5 \n",
      "Numero de categorias para variavel 'r_emaildomain': 29 \n"
     ]
    }
   ],
   "source": [
    "for data in ['X_train', 'X_test']:\n",
    "    categories_dict = {}\n",
    "    print('\\r\\nchecking number of categories for {}'. format(data))\n",
    "    for cat in ord_dict[data].columns:\n",
    "        if ord_dict[data][cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(ord_dict[data][cat].unique())\n",
    "            print(\"Numero de categorias para variavel '{}': {} \".format(cat, ord_dict[data][cat].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactiondt</th>\n",
       "      <th>transactionamt</th>\n",
       "      <th>productcd</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>...</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>if_anomaly</th>\n",
       "      <th>transactionamt_to_mean_card1</th>\n",
       "      <th>transactionamt_to_mean_card4</th>\n",
       "      <th>transactionamt_to_std_card1</th>\n",
       "      <th>transactionamt_to_std_card4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3486774</th>\n",
       "      <td>13107389.0</td>\n",
       "      <td>38.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9633.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.239972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.497537</td>\n",
       "      <td>0.124312</td>\n",
       "      <td>0.507226</td>\n",
       "      <td>0.965394</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845360</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.160854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062695</th>\n",
       "      <td>1650884.0</td>\n",
       "      <td>150.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15063.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491038</td>\n",
       "      <td>0.463338</td>\n",
       "      <td>0.110642</td>\n",
       "      <td>0.328999</td>\n",
       "      <td>0.869981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598610</td>\n",
       "      <td>1.105924</td>\n",
       "      <td>0.356718</td>\n",
       "      <td>0.634016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273443</th>\n",
       "      <td>7048761.0</td>\n",
       "      <td>56.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9006.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384445</th>\n",
       "      <td>10011292.0</td>\n",
       "      <td>8.459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.433901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533395</td>\n",
       "      <td>0.454835</td>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.444016</td>\n",
       "      <td>0.857350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190744</td>\n",
       "      <td>0.062367</td>\n",
       "      <td>0.289492</td>\n",
       "      <td>0.035754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489059</th>\n",
       "      <td>13159069.0</td>\n",
       "      <td>77.950</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7919.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854398</td>\n",
       "      <td>0.616348</td>\n",
       "      <td>0.775027</td>\n",
       "      <td>0.323443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transactiondt  transactionamt  productcd    card1  card2  card3  \\\n",
       "id                                                                         \n",
       "3486774     13107389.0          38.056        0.0   9633.0  130.0  185.0   \n",
       "3062695      1650884.0         150.000        1.0  15063.0  514.0  150.0   \n",
       "3273443      7048761.0          56.500        2.0   9006.0  555.0  143.0   \n",
       "3384445     10011292.0           8.459        0.0  11201.0  103.0  185.0   \n",
       "3489059     13159069.0          77.950        2.0   7919.0  194.0  150.0   \n",
       "\n",
       "         card4  card5  card6       addr1  ...        m5        m6        m7  \\\n",
       "id                                        ...                                 \n",
       "3486774    0.0  138.0    0.0  270.239972  ...  0.520700  0.497537  0.124312   \n",
       "3062695    0.0  226.0    1.0  194.000000  ...  0.491038  0.463338  0.110642   \n",
       "3273443    1.0  224.0    0.0  502.000000  ...  0.000000  0.342737  0.000000   \n",
       "3384445    0.0  226.0    0.0  300.433901  ...  0.533395  0.454835  0.116979   \n",
       "3489059    1.0  166.0    0.0  315.000000  ...  0.345176  1.000000  0.000000   \n",
       "\n",
       "               m8        m9  if_anomaly  transactionamt_to_mean_card1  \\\n",
       "id                                                                      \n",
       "3486774  0.507226  0.965394           1                      0.845360   \n",
       "3062695  0.328999  0.869981           1                      0.598610   \n",
       "3273443  0.000000  1.000000           1                      1.000000   \n",
       "3384445  0.444016  0.857350           1                      0.190744   \n",
       "3489059  0.000000  0.000000           1                      0.854398   \n",
       "\n",
       "         transactionamt_to_mean_card4  transactionamt_to_std_card1  \\\n",
       "id                                                                   \n",
       "3486774                      0.280580                     0.710967   \n",
       "3062695                      1.105924                     0.356718   \n",
       "3273443                      0.446743                          NaN   \n",
       "3384445                      0.062367                     0.289492   \n",
       "3489059                      0.616348                     0.775027   \n",
       "\n",
       "         transactionamt_to_std_card4  \n",
       "id                                    \n",
       "3486774                     0.160854  \n",
       "3062695                     0.634016  \n",
       "3273443                     0.234439  \n",
       "3384445                     0.035754  \n",
       "3489059                     0.323443  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_dict['X_train'], ord_dict['X_test'] = ordinal_encode(ord_dict['X_train'], ord_dict['X_test'], testing = False)\n",
    "\n",
    "ord_dict['X_train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of columns before one-hot encoding: 50\n",
      "Quantity of columns after one-hot encoding: 146\n",
      "Quantity of columns before one-hot encoding: 58\n",
      "Quantity of columns after one-hot encoding: 135\n",
      "\r\n",
      "Columns of the new database:\n"
     ]
    }
   ],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    onehot_dict[df] = one_hot_encode(onehot_dict[df])\n",
    "    \n",
    "print('\\r\\nColumns of the new database:')\n",
    "# print(onehot_dict[df].columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# report new data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_vars_df = pd.DataFrame([c for c in onehot_dict['X_train'].columns.to_list() if c.startswith('dummy')])\n",
    "report_df = pd.concat([report_df,dummy_vars_df], ignore_index=True, axis=1)\n",
    "report_df.columns = ['numerical_cols', 'non_numerical_cols', 'dummy_cols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data alignment\n",
    "if some category is missing on test set, we need to account for that and build corresponding column filled with 'zeros'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_cols(smaller, greater):\n",
    "    missing_cols = set( greater.columns ) - set( smaller.columns )\n",
    "    for c in missing_cols:\n",
    "        smaller[c] = 0\n",
    "    \n",
    "    return smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_dict['X_train'] = fill_missing_cols(onehot_dict['X_train'], onehot_dict['X_test'])\n",
    "onehot_dict['X_test'] = fill_missing_cols(onehot_dict['X_test'], onehot_dict['X_train'])\n",
    "\n",
    "# align column positions (no data leakage here. Just altering column ordering.)\n",
    "onehot_dict['X_train'], onehot_dict['X_test'] = onehot_dict['X_train'].align(onehot_dict['X_test'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 50)\n",
      "(7000, 162)\n",
      "(3000, 58)\n",
      "(3000, 162)\n"
     ]
    }
   ],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    ord_dict[df].to_csv(os.path.join(outputs, df+'.csv'))\n",
    "    onehot_dict[df].to_csv(os.path.join(outputs, df+'_onehot.csv'))\n",
    "    \n",
    "for df in ['X_train', 'X_test']:\n",
    "    print(ord_dict[df].shape)\n",
    "    print(onehot_dict[df].shape)\n",
    "    \n",
    "y_train.to_csv(os.path.join(outputs, 'y_train.csv'))\n",
    "y_test.to_csv(os.path.join(outputs, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save report over data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df.to_csv(os.path.join(reports, 'data_types.csv'), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
