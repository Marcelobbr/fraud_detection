{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, df_test, testing = False):\n",
    "#     df = df.copy()\n",
    "    categories_dict = {}\n",
    "    \n",
    "    temp_merge = df.append(df_test)\n",
    "    for cat in temp_merge.columns:\n",
    "        if temp_merge[cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(temp_merge[cat].unique())\n",
    "            if testing:\n",
    "                print(\"Numero de categorias para variavel '{}': {} \".format(cat,temp_merge[cat].unique().size))\n",
    "\n",
    "    if testing:\n",
    "        print()\n",
    "        print(list(categories_dict.keys()))\n",
    "        \n",
    "    enc = OrdinalEncoder(categories=list(categories_dict.values()))\n",
    "    trained_encoder = enc.fit(df[list(categories_dict.keys())])\n",
    "    \n",
    "    # transform train and test\n",
    "    df[list(categories_dict.keys())] = trained_encoder.transform(df[list(categories_dict.keys())])\n",
    "    df_test[list(categories_dict.keys())] = trained_encoder.transform(df_test[list(categories_dict.keys())])\n",
    "\n",
    "    if testing:\n",
    "        print(categories_dict)\n",
    "    \n",
    "    return df, df_test\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    print('Quantity of columns before one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    df_oldcols = df.columns.to_list()\n",
    "    df = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n",
    "    \n",
    "    print('Quantity of columns after one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    # rename columns to show which are dummies\n",
    "    onehot_cols = list(set(df.columns.to_list()) - set(df_oldcols))\n",
    "    onehot_cols_renaming = {col: 'dummy_'+col.replace('-', '_') for col in onehot_cols}\n",
    "    df.rename(columns = onehot_cols_renaming, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = os.path.join('..', 'data', '02_intermediate')\n",
    "outputs = os.path.join('..', 'data', '03_processed')\n",
    "reports = os.path.join('..', 'data', '06_reporting')\n",
    "\n",
    "ord_dict = {}\n",
    "ord_dict['X_train'] = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "ord_dict['X_test'] = pd.read_csv(os.path.join(inputs, 'X_test.csv'), index_col='id')\n",
    "\n",
    "onehot_dict = copy.deepcopy(ord_dict)\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id') \n",
    "y_test = pd.read_csv(os.path.join(inputs, 'y_test.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df = pd.read_csv(os.path.join(reports, 'data_types.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count categorical data unique values\n",
    "Check both train and test. Any inconsistency between them should be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "checking number of categories for X_train\n",
      "Numero de categorias para variavel 'productcd': 5 \n",
      "Numero de categorias para variavel 'card4': 5 \n",
      "Numero de categorias para variavel 'card6': 3 \n",
      "Numero de categorias para variavel 'p_emaildomain': 55 \n",
      "Numero de categorias para variavel 'r_emaildomain': 41 \n",
      "Numero de categorias para variavel 'm4': 4 \n",
      "\r\n",
      "checking number of categories for X_test\n",
      "Numero de categorias para variavel 'card4': 5 \n",
      "Numero de categorias para variavel 'card6': 3 \n",
      "Numero de categorias para variavel 'm4': 4 \n",
      "Numero de categorias para variavel 'p_emaildomain': 36 \n",
      "Numero de categorias para variavel 'productcd': 5 \n",
      "Numero de categorias para variavel 'r_emaildomain': 22 \n"
     ]
    }
   ],
   "source": [
    "for data in ['X_train', 'X_test']:\n",
    "    categories_dict = {}\n",
    "    print('\\r\\nchecking number of categories for {}'. format(data))\n",
    "    for cat in ord_dict[data].columns:\n",
    "        if ord_dict[data][cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(ord_dict[data][cat].unique())\n",
    "            print(\"Numero de categorias para variavel '{}': {} \".format(cat, ord_dict[data][cat].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-72886db3a5f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mordinal_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-c7e0a7989614>\u001b[0m in \u001b[0;36mordinal_encode\u001b[1;34m(df, df_test, testing)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrained_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# transform train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \"\"\"\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[1;32m---> 61\u001b[1;33m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 645\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "ord_dict['X_train'], ord_dict['X_test'] = ordinal_encode(ord_dict['X_train'], ord_dict['X_test'], testing = False)\n",
    "\n",
    "ord_dict['X_train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    onehot_dict[df] = one_hot_encode(onehot_dict[df])\n",
    "    \n",
    "print('\\r\\nColumns of the new database:')\n",
    "# print(onehot_dict[df].columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# report new data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_vars_df = pd.DataFrame([c for c in onehot_dict['X_train'].columns.to_list() if c.startswith('dummy')])\n",
    "report_df = pd.concat([report_df,dummy_vars_df], ignore_index=True, axis=1)\n",
    "report_df.columns = ['numerical_cols', 'non_numerical_cols', 'dummy_cols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data alignment\n",
    "if some category is missing on test set, we need to account for that and build corresponding column filled with 'zeros'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_cols(smaller, greater):\n",
    "    missing_cols = set( greater.columns ) - set( smaller.columns )\n",
    "    for c in missing_cols:\n",
    "        smaller[c] = 0\n",
    "    \n",
    "    return smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_dict['X_train'] = fill_missing_cols(onehot_dict['X_train'], onehot_dict['X_test'])\n",
    "onehot_dict['X_test'] = fill_missing_cols(onehot_dict['X_test'], onehot_dict['X_train'])\n",
    "\n",
    "# align column positions (no data leakage here. Just altering column ordering.)\n",
    "onehot_dict['X_train'], onehot_dict['X_test'] = onehot_dict['X_train'].align(onehot_dict['X_test'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    ord_dict[df].to_csv(os.path.join(outputs, df+'.csv'))\n",
    "    onehot_dict[df].to_csv(os.path.join(outputs, df+'_onehot.csv'))\n",
    "    \n",
    "for df in ['X_train', 'X_test']:\n",
    "    print(ord_dict[df].shape)\n",
    "    print(onehot_dict[df].shape)\n",
    "    \n",
    "y_train.to_csv(os.path.join(outputs, 'y_train.csv'))\n",
    "y_test.to_csv(os.path.join(outputs, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save report over data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df.to_csv(os.path.join(reports, 'data_types.csv'), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
