{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join('..', 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)\n",
    "\n",
    "from model import get_model_params, timer, measure_prediction_time, apply_ml_model, save_model_parameters, save_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set model parameters and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 13)\n",
      "(559, 20)\n",
      "(559, 1)\n"
     ]
    }
   ],
   "source": [
    "# scoring = 'neg_mean_squared_error'\n",
    "scoring = 'f1'\n",
    "\n",
    "inputs = os.path.join('..', 'data', '03_processed')\n",
    "models_reports = os.path.join('..', 'data', '04_models')\n",
    "model_outputs = os.path.join('..', 'data', '05_model_output')\n",
    "reports = os.path.join('..', 'data', '06_reporting')\n",
    "\n",
    "X_train            = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "X_train_onehot         = pd.read_csv(os.path.join(inputs, 'X_train_onehot.csv'), index_col='id')\n",
    "y_train            = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id')\n",
    "\n",
    "data_list = [X_train, X_train_onehot, y_train]\n",
    "\n",
    "for df in data_list:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly_count_lag10</th>\n",
       "      <th>cycle</th>\n",
       "      <th>dummy_preset_1_2</th>\n",
       "      <th>dummy_preset_1_3</th>\n",
       "      <th>dummy_preset_2_2</th>\n",
       "      <th>dummy_preset_2_3</th>\n",
       "      <th>dummy_preset_2_4</th>\n",
       "      <th>dummy_preset_2_5</th>\n",
       "      <th>dummy_preset_2_6</th>\n",
       "      <th>dummy_preset_2_7</th>\n",
       "      <th>dummy_preset_2_8</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>vibrationx</th>\n",
       "      <th>vibrationy</th>\n",
       "      <th>vibrationz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.483250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.657254</td>\n",
       "      <td>44.235186</td>\n",
       "      <td>46.441769</td>\n",
       "      <td>64.820327</td>\n",
       "      <td>66.454520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.228715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.172076</td>\n",
       "      <td>60.807234</td>\n",
       "      <td>62.005951</td>\n",
       "      <td>80.714431</td>\n",
       "      <td>81.246405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.993479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.032190</td>\n",
       "      <td>79.027536</td>\n",
       "      <td>82.642110</td>\n",
       "      <td>98.254386</td>\n",
       "      <td>98.785196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.315567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.508634</td>\n",
       "      <td>79.716242</td>\n",
       "      <td>122.362321</td>\n",
       "      <td>121.363429</td>\n",
       "      <td>118.652538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.245166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.764833</td>\n",
       "      <td>39.989054</td>\n",
       "      <td>42.514302</td>\n",
       "      <td>61.037910</td>\n",
       "      <td>50.716469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anomaly_count_lag10  cycle  dummy_preset_1_2  dummy_preset_1_3  \\\n",
       "id                                                                   \n",
       "0                   0.0    1.0                 0                 1   \n",
       "1                   0.0    2.0                 1                 0   \n",
       "2                   0.0    3.0                 1                 0   \n",
       "3                   0.0    4.0                 1                 0   \n",
       "4                   0.0    5.0                 1                 0   \n",
       "\n",
       "    dummy_preset_2_2  dummy_preset_2_3  dummy_preset_2_4  dummy_preset_2_5  \\\n",
       "id                                                                           \n",
       "0                  0                 0                 0                 0   \n",
       "1                  0                 0                 1                 0   \n",
       "2                  0                 0                 0                 0   \n",
       "3                  0                 1                 0                 0   \n",
       "4                  0                 0                 0                 1   \n",
       "\n",
       "    dummy_preset_2_6  dummy_preset_2_7  dummy_preset_2_8  frequency  lag_1  \\\n",
       "id                                                                           \n",
       "0                  1                 0                 0  44.483250      0   \n",
       "1                  0                 0                 0  60.228715      0   \n",
       "2                  0                 0                 0  80.993479      0   \n",
       "3                  0                 0                 0  80.315567      0   \n",
       "4                  0                 0                 0  64.245166      0   \n",
       "\n",
       "    lag_2  lag_3    pressure  temperature  vibrationx  vibrationy  vibrationz  \n",
       "id                                                                             \n",
       "0       0      0   47.657254    44.235186   46.441769   64.820327   66.454520  \n",
       "1       0      0   63.172076    60.807234   62.005951   80.714431   81.246405  \n",
       "2       0      0   83.032190    79.027536   82.642110   98.254386   98.785196  \n",
       "3       0      0  100.508634    79.716242  122.362321  121.363429  118.652538  \n",
       "4       0      0   51.764833    39.989054   42.514302   61.037910   50.716469  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convergence warning: https://stackoverflow.com/questions/20681864/lasso-on-sklearn-does-not-converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dict = {}\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "# if target_type == 'regression':\n",
    "#     parameters = {\n",
    "#     'model__alpha': np.linspace(0.2, 1, 5), \n",
    "#     'model__l1_ratio': np.linspace(0, 1, 5),\n",
    "#     'model__random_state':[42]\n",
    "#     }\n",
    "#     ml_model = ElasticNet()\n",
    "#     # set tol, default is 1e-4\n",
    "#     do_transform_label = 'log'\n",
    "# elif target_type == 'binary':\n",
    "c_space = np.logspace(-5, 1, 5)\n",
    "parameters = {\n",
    "'model__C': c_space, \n",
    "'model__penalty': ['l2'],\n",
    "'model__random_state':[42]\n",
    "}\n",
    "ml_model = LogisticRegression()\n",
    "do_transform_label = None\n",
    "\n",
    "# key = 'standard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with different preprocessing steps\n",
    "There are 2 different X_sets: On X_train_onehot, I applied one-hot encoding, while on X_train I applied Ordinal Encoding. The former is aimed at linear regression models, and the later is generally used for tree models.\n",
    "\n",
    "On 'column' parameter, I am able to choose column groups. For instance, I might exclude collinear variables obtained from the VIF function applied on notebook 5. That is useful for linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "treat_collinearity = False, do_build_polynomals=False, do_treat_skewness=False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test type: False\n",
      "{'reg': {'best_params': {'model__C': 0.31622776601683794,\n",
      "                         'model__penalty': 'l2',\n",
      "                         'model__random_state': 42},\n",
      "         'best_score': 0.5520445344129555,\n",
      "         'prediction_time': 0.0003005,\n",
      "         'train_time': 0.548985}}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'reg'\n",
    "ml_dict[model_type] = {}\n",
    "columns = X_train_onehot.columns\n",
    "\n",
    "clf, ml_dict[model_type]['train_time'], ml_dict[model_type]['prediction_time'] = apply_ml_model(\n",
    "    X_train_onehot, y_train, columns, ml_model, parameters, scoring,\n",
    "    do_build_polynomals=False, \n",
    "    do_treat_skewness=False,\n",
    "    imputation=Imputer(strategy='median'), scaler=StandardScaler(),\n",
    "    )\n",
    "ml_dict[model_type]['best_params'], ml_dict[model_type]['best_score']  = get_model_params(clf, scoring)\n",
    "pprint(ml_dict)\n",
    "\n",
    "save_model_parameters(models_reports, model_type, clf)\n",
    "save_model_metrics(model_outputs, model_type, ml_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "treat_collinearity = True, do_build_polynomals=False, do_treat_skewness=False,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test type: False\n",
      "{'reg': {'best_params': {'model__C': 0.31622776601683794,\n",
      "                         'model__penalty': 'l2',\n",
      "                         'model__random_state': 42},\n",
      "         'best_score': 0.5520445344129555,\n",
      "         'prediction_time': 0.0003005,\n",
      "         'train_time': 0.548985},\n",
      " 'reg_nocol': {'best_params': {'model__C': 0.31622776601683794,\n",
      "                               'model__penalty': 'l2',\n",
      "                               'model__random_state': 42},\n",
      "               'best_score': 0.5520445344129555,\n",
      "               'prediction_time': 0.0002999,\n",
      "               'train_time': 0.507}}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'reg_nocol'\n",
    "ml_dict[model_type] = {}\n",
    "\n",
    "# columns_nocol = dfs_dict['X_train_oh_nocol'].columns.to_list()\n",
    "\n",
    "clf, ml_dict[model_type]['train_time'], ml_dict[model_type]['prediction_time'] = apply_ml_model(\n",
    "    X_train_onehot, y_train, columns, ml_model, parameters, scoring,\n",
    "    do_build_polynomals=False, \n",
    "    do_treat_skewness=False,\n",
    "    imputation=Imputer(strategy='median'), scaler=StandardScaler(),\n",
    "    )\n",
    "ml_dict[model_type]['best_params'], ml_dict[model_type]['best_score']  = get_model_params(clf, scoring)\n",
    "pprint(ml_dict)\n",
    "\n",
    "save_model_parameters(models_reports, model_type, clf)\n",
    "save_model_metrics(model_outputs, model_type, ml_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I might use the alternative encoding just to demonstrate the impact on the score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
